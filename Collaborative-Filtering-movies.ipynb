{"cells":[{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["# Collaborative Filtering\n","\n","\n","## Objectives\n","Create recommendation system based on collaborative filtering\n","Recommendation systems are a collection of algorithms used to recommend items to users based on information taken from the user. These systems have become ubiquitous and can be commonly seen in online stores, movies databases and job finders. In this notebook, we will explore recommendation systems based on Collaborative Filtering and implement simple version of one using Python and the Pandas library.\n","\n"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["<h1>Table of contents</h1>\n","\n","<div>\n","    <ol>\n","        <li>Acquiring the Data</li>\n","        <li>Preprocessing</li>\n","        <li>Collaborative Filtering</li>\n","    </ol>\n","</div>\n","<br>\n","<hr>\n"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["# Acquiring the Data\n","To acquire and extract the data, simply run the following Bash scripts:\\\n","Dataset acquired from [GroupLens](http://grouplens.org/datasets/movielens/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2021-01-01)."]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["First, let's get all of the imports out of the way:\n"]},{"cell_type":"code","execution_count":1,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["import pandas as pd\n","from math import sqrt\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["Now let's read each file into their Dataframes:\n"]},{"cell_type":"code","execution_count":2,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["movies_df = pd.read_csv('https://raw.githubusercontent.com/RichardOsei/ML/main/movies.csv')\n","ratings_df = pd.read_csv('ratings.csv')"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["# Preprocessing\n","Let's also take a peek at how each of them are organized:"]},{"cell_type":"code","execution_count":3,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>movieId</th>\n","      <th>title</th>\n","      <th>genres</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Toy Story (1995)</td>\n","      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Jumanji (1995)</td>\n","      <td>Adventure|Children|Fantasy</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Grumpier Old Men (1995)</td>\n","      <td>Comedy|Romance</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Waiting to Exhale (1995)</td>\n","      <td>Comedy|Drama|Romance</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Father of the Bride Part II (1995)</td>\n","      <td>Comedy</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   movieId                               title   \n","0        1                    Toy Story (1995)  \\\n","1        2                      Jumanji (1995)   \n","2        3             Grumpier Old Men (1995)   \n","3        4            Waiting to Exhale (1995)   \n","4        5  Father of the Bride Part II (1995)   \n","\n","                                        genres  \n","0  Adventure|Animation|Children|Comedy|Fantasy  \n","1                   Adventure|Children|Fantasy  \n","2                               Comedy|Romance  \n","3                         Comedy|Drama|Romance  \n","4                                       Comedy  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["movies_df.head()"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["So each movie has a unique ID, a title with its release year along with it (Which may contain unicode characters) and several different genres in the same field. Let's remove the year from the title column and place it into its own one by using the handy function that Pandas has.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["Let's remove the year from the **title** column and store it in a new **year** column.\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>movieId</th>\n","      <th>title</th>\n","      <th>genres</th>\n","      <th>year</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Toy Story</td>\n","      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n","      <td>1995</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Jumanji</td>\n","      <td>Adventure|Children|Fantasy</td>\n","      <td>1995</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Grumpier Old Men</td>\n","      <td>Comedy|Romance</td>\n","      <td>1995</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Waiting to Exhale</td>\n","      <td>Comedy|Drama|Romance</td>\n","      <td>1995</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Father of the Bride Part II</td>\n","      <td>Comedy</td>\n","      <td>1995</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   movieId                        title   \n","0        1                    Toy Story  \\\n","1        2                      Jumanji   \n","2        3             Grumpier Old Men   \n","3        4            Waiting to Exhale   \n","4        5  Father of the Bride Part II   \n","\n","                                        genres  year  \n","0  Adventure|Animation|Children|Comedy|Fantasy  1995  \n","1                   Adventure|Children|Fantasy  1995  \n","2                               Comedy|Romance  1995  \n","3                         Comedy|Drama|Romance  1995  \n","4                                       Comedy  1995  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["movies_df[['title', 'year']] = movies_df['title'].str.extract(r'^(.*?)\\s\\((\\d{4})\\)$', expand=True)\n","movies_df.head()\n"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["With that, let's also drop the genres column since we won't need it for this particular recommendation system.\n"]},{"cell_type":"code","execution_count":5,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"scrolled":false},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>movieId</th>\n","      <th>title</th>\n","      <th>year</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Toy Story</td>\n","      <td>1995</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Jumanji</td>\n","      <td>1995</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Grumpier Old Men</td>\n","      <td>1995</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Waiting to Exhale</td>\n","      <td>1995</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Father of the Bride Part II</td>\n","      <td>1995</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   movieId                        title  year\n","0        1                    Toy Story  1995\n","1        2                      Jumanji  1995\n","2        3             Grumpier Old Men  1995\n","3        4            Waiting to Exhale  1995\n","4        5  Father of the Bride Part II  1995"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["#Dropping the genres column\n","movies_df = movies_df.drop(columns=['genres'])\n","movies_df.head()"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["Next, let's look at the ratings dataframe.\n"]},{"cell_type":"code","execution_count":6,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>userId</th>\n","      <th>movieId</th>\n","      <th>rating</th>\n","      <th>timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>169</td>\n","      <td>2.5</td>\n","      <td>1204927694</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2471</td>\n","      <td>3.0</td>\n","      <td>1204927438</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>48516</td>\n","      <td>5.0</td>\n","      <td>1204927435</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>2571</td>\n","      <td>3.5</td>\n","      <td>1436165433</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>109487</td>\n","      <td>4.0</td>\n","      <td>1436165496</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   userId  movieId  rating   timestamp\n","0       1      169     2.5  1204927694\n","1       1     2471     3.0  1204927438\n","2       1    48516     5.0  1204927435\n","3       2     2571     3.5  1436165433\n","4       2   109487     4.0  1436165496"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["ratings_df.head()"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["Every row in the ratings dataframe has a user id associated with at least one movie, a rating and a timestamp showing when they reviewed it. We won't be needing the timestamp column, so let's drop it to save on memory.\n"]},{"cell_type":"code","execution_count":7,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>userId</th>\n","      <th>movieId</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>169</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2471</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>48516</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>2571</td>\n","      <td>3.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>109487</td>\n","      <td>4.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   userId  movieId  rating\n","0       1      169     2.5\n","1       1     2471     3.0\n","2       1    48516     5.0\n","3       2     2571     3.5\n","4       2   109487     4.0"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["#Drop removes a specified row or column from a dataframe\n","ratings_df = ratings_df.drop(columns=['timestamp'])\n","ratings_df.head()"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["<hr>\n","\n","<a id=\"ref3\"></a>\n","\n","# Collaborative Filtering\n"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["**Collaborative Filtering**, also known as **User-User Filtering**. As hinted by its alternate name, this technique uses other users to recommend items to the input user. It attempts to find users that have similar preferences and opinions as the input and then recommends items that they have liked to the input. There are several methods of finding similar users (Even some making use of Machine Learning), and the one we will be using here is going to be based on the **Pearson Correlation Function**.\n","\n","<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%205/images/User_Item.png\" width=800px>\n","\n","The process for creating a User Based recommendation system is as follows:\n","\n","*   Select a user with the movies the user has watched\n","*   Based on his rating of the movies, find the top X neighbours\n","*   Get the watched movie record of the user for each neighbour\n","*   Calculate a similarity score using some formula\n","*   Recommend the items with the highest score\n","\n","Let's begin by creating an input user to recommend movies to:\n","\n","Notice: To add more movies, simply increase the amount of elements in the userInput. Feel free to add more in! Just be sure to write it in with capital letters and if a movie starts with a \"The\", like \"The Matrix\" then write it in like this: 'Matrix, The' .\n"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["userInput = [\n","            {'title':'Breakfast Club, The', 'rating':5},\n","            {'title':'Toy Story', 'rating':3.5},\n","            {'title':'Jumanji', 'rating':2},\n","            {'title':\"Pulp Fiction\", 'rating':5},\n","            {'title':'Akira', 'rating':4.5}\n","         ] \n","inputdata = pd.DataFrame(userInput)\n","inputdata"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["#### Add movieId to input user\n","\n","With the input complete, let's extract the input movies's ID's from the movies dataframe and add them into it.\n","\n","We can achieve this by first filtering out the rows that contain the input movies' title and then merging this subset with the input dataframe. We also drop unnecessary columns for the input to save memory space.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inputId = movies_df[movies_df['title'].isin(inputdata['title'].tolist())]\n","inputId"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inputdata"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"scrolled":true},"outputs":[],"source":["#Filtering out the movies by title\n","inputId = movies_df[movies_df['title'].isin(inputdata['title'].tolist())]\n","#Then merging it so we can get the movieId. It's implicitly merging it by title.\n","inputdata = pd.merge(inputId, inputdata)\n","#Dropping information we won't use from the input dataframe\n","inputdata = inputdata.drop(columns=['year'])\n","inputdata"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["#### The users who has seen the same movies\n","\n","Now with the movie ID's in our input, we can now get the subset of users that have watched and reviewed the movies in our input.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["#Filtering out users that have watched movies that the input has watched and storing it\n","userSubset = ratings_df[ratings_df['movieId'].isin(inputdata['movieId'].tolist())]\n","userSubset.shape\n"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["We now group up the rows by user ID.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["#Groupby creates several sub dataframes where they all have the same value in the column specified as the parameter\n","userSubsetGroup = userSubset.groupby(['userId'])"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["Let's look at one of the users, e.g. the one with userID=1130.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["userSubsetGroup.get_group(1130)"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["Let's also sort these groups so the users that share the most movies in common with the input have higher priority. This provides a richer recommendation since we won't go through every single user.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["#Sorting it so users with movie most in common with the input will have priority\n","userSubsetGroup = sorted(userSubsetGroup,  key=lambda x: len(x[1]), reverse=True)"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["Now let's look at the first user.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["userSubsetGroup[0:3]"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["#### Similarity of users to input user\n","\n","Next, we are going to compare all users (not really all !!!) to our specified user and find the one that is most similar.\\\n","We're going to find out how similar each user is to the input through the **Pearson Correlation Coefficient**. It is used to measure the strength of a linear association between the two variables. The formula for finding this coefficient between sets X and Y with N values can be seen in the image below.\n","\n","Why Pearson Correlation?\n","\n","Pearson correlation is invariant to scaling, i.e. multiplying all elements by a nonzero constant or adding any constant to all elements. For example, if you have two vectors X and Y, then, pearson(X, Y) == pearson(X, 2 \\* Y + 3). This is a pretty important property in recommendation systems because, for example, two users might rate two series of items totally differently in terms of absolute rates, but they would be similar users (i.e. with similar ideas) with similar rates in various scales .\n","\n","![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/bd1ccc2979b0fd1c1aec96e386f686ae874f9ec0 \"Pearson Correlation\")\n","\n","The values given by the formula vary from r = -1 to r = 1, where 1 forms a direct correlation between the two entities (it means a perfect positive correlation) and -1 forms a perfect negative correlation.\n","\n","In our case, a 1 means that the two users have similar tastes while a -1 means the opposite.\n"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["We will select a subset of users to iterate through. This limit is imposed because we don't want to waste too much time going through every single user.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["userSubsetGroup = userSubsetGroup[0:100]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["userSubsetGroup"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["Now, we calculate the Pearson Correlation between input user and subset group, and store it in a dictionary, where the key is the user Id and the value is the coefficient.\n"]},{"cell_type":"code","execution_count":21,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"scrolled":true},"outputs":[],"source":["#Store the Pearson Correlation in a dictionary, where the key is the user Id and the value is the coefficient\n","pearsonCorrelationDict = {}\n","\n","#For every user group in our subset\n","for name, group in userSubsetGroup:\n","    #Let's start by sorting the input and current user group so the values aren't mixed up later on\n","    group = group.sort_values(by='movieId')\n","    inputdata = inputdata.sort_values(by='movieId')\n","    #Get the N for the formula\n","    nRatings = len(group)\n","    #Get the review scores for the movies that they both have in common\n","    temp_df = inputdata[inputdata['movieId'].isin(group['movieId'].tolist())]\n","    #And then store them in a temporary buffer variable in a list format to facilitate future calculations\n","    tempRatingList = temp_df['rating'].tolist()\n","    #Let's also put the current user group reviews in a list format\n","    tempGroupList = group['rating'].tolist()\n","    #Now let's calculate the pearson correlation between two users, so called, x and y\n","    Sxx = sum([i**2 for i in tempRatingList]) - pow(sum(tempRatingList),2)/float(nRatings)\n","    Syy = sum([i**2 for i in tempGroupList]) - pow(sum(tempGroupList),2)/float(nRatings)\n","    Sxy = sum( i*j for i, j in zip(tempRatingList, tempGroupList)) - sum(tempRatingList)*sum(tempGroupList)/float(nRatings)\n","    \n","    #If the denominator is different than zero, then divide, else, 0 correlation.\n","    if Sxx != 0 and Syy != 0:\n","        pearsonCorrelationDict[name] = Sxy/sqrt(Sxx*Syy)\n","    else:\n","        pearsonCorrelationDict[name] = 0\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["dict_items([((75,), 0.8272781516947562), ((106,), 0.5860090386731182), ((686,), 0.8320502943378437), ((815,), 0.5765566601970551), ((1040,), 0.9434563530497265), ((1130,), 0.2891574659831201), ((1502,), 0.8770580193070299), ((1599,), 0.4385290096535153), ((1625,), 0.716114874039432), ((1950,), 0.179028718509858), ((2065,), 0.4385290096535153), ((2128,), 0.5860090386731196), ((2432,), 0.1386750490563073), ((2791,), 0.8770580193070299), ((2839,), 0.8204126541423674), ((2948,), -0.11720180773462392), ((3025,), 0.45124262819713973), ((3040,), 0.89514359254929), ((3186,), 0.6784622064861935), ((3271,), 0.26989594817970664), ((3429,), 0.0), ((3734,), -0.15041420939904673), ((4099,), 0.05860090386731196), ((4208,), 0.29417420270727607), ((4282,), -0.4385290096535115), ((4292,), 0.6564386345361464), ((4415,), -0.11183835382312353), ((4586,), -0.9024852563942795), ((4725,), -0.08006407690254357), ((4818,), 0.4885967564883424), ((5104,), 0.7674257668936507), ((5165,), -0.4385290096535153), ((5547,), 0.17200522903844556), ((6082,), -0.04728779924109591), ((6207,), 0.9615384615384616), ((6366,), 0.6577935144802716), ((6482,), 0.0), ((6530,), -0.3516054232038709), ((7235,), 0.6981407669689391), ((7403,), 0.11720180773462363), ((7641,), 0.7161148740394331), ((7996,), 0.626600514784504), ((8008,), -0.22562131409856986), ((8086,), 0.6933752452815365), ((8245,), 0.0), ((8572,), 0.8600261451922278), ((8675,), 0.5370861555295773), ((9101,), -0.08600261451922278), ((9358,), 0.692178738358485), ((9663,), 0.193972725041952), ((9994,), 0.5030272728659587), ((10248,), -0.24806946917841693), ((10315,), 0.537086155529574), ((10368,), 0.4688072309384945), ((10607,), 0.41602514716892186), ((10707,), 0.9615384615384616), ((10863,), 0.6020183016345595), ((11314,), 0.8204126541423654), ((11399,), 0.517260600111872), ((11769,), 0.9376144618769914), ((11827,), 0.4902903378454601), ((12069,), 0.0), ((12120,), 0.9292940047327363), ((12211,), 0.8600261451922278), ((12325,), 0.9616783115081544), ((12916,), 0.5860090386731196), ((12921,), 0.6611073566849309), ((13053,), 0.9607689228305227), ((13142,), 0.6016568375961863), ((13260,), 0.7844645405527362), ((13366,), 0.8951435925492911), ((13768,), 0.8770580193070289), ((13888,), 0.2508726030021272), ((13923,), 0.3516054232038718), ((13934,), 0.17200522903844556), ((14529,), 0.7417901772340937), ((14551,), 0.537086155529574), ((14588,), 0.21926450482675766), ((14984,), 0.716114874039432), ((15137,), 0.5860090386731196), ((15157,), 0.9035841064985974), ((15466,), 0.7205766921228921), ((15670,), 0.516015687115336), ((15834,), 0.22562131409856986), ((16292,), 0.6577935144802716), ((16456,), 0.7161148740394331), ((16506,), 0.5481612620668942), ((17246,), 0.48038446141526137), ((17438,), 0.7093169886164387), ((17501,), 0.8168748513121271), ((17502,), 0.8272781516947562), ((17666,), 0.7689238340176859), ((17735,), 0.7042381820123422), ((17742,), 0.3922322702763681), ((17757,), 0.64657575013984), ((17854,), 0.537086155529574), ((17897,), 0.8770580193070289), ((17944,), 0.2713848825944774), ((18301,), 0.29838119751643016), ((18509,), 0.1322214713369862)])"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["pearsonCorrelationDict.items()"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>similarityIndex</th>\n","      <th>userId</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.827278</td>\n","      <td>(75,)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.586009</td>\n","      <td>(106,)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.832050</td>\n","      <td>(686,)</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.576557</td>\n","      <td>(815,)</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.943456</td>\n","      <td>(1040,)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   similarityIndex   userId\n","0         0.827278    (75,)\n","1         0.586009   (106,)\n","2         0.832050   (686,)\n","3         0.576557   (815,)\n","4         0.943456  (1040,)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["pearsonDF = pd.DataFrame.from_dict(pearsonCorrelationDict, orient='index')\n","pearsonDF.columns = ['similarityIndex']\n","pearsonDF['userId'] = pearsonDF.index\n","pearsonDF.index = range(len(pearsonDF))\n","pearsonDF.head()"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["#### The top x similar users to input user\n","\n","Now let's get the top 50 users that are most similar to the input.\n"]},{"cell_type":"code","execution_count":24,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>similarityIndex</th>\n","      <th>userId</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>64</th>\n","      <td>0.961678</td>\n","      <td>(12325,)</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>0.961538</td>\n","      <td>(6207,)</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>0.961538</td>\n","      <td>(10707,)</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>0.960769</td>\n","      <td>(13053,)</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.943456</td>\n","      <td>(1040,)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    similarityIndex    userId\n","64         0.961678  (12325,)\n","34         0.961538   (6207,)\n","55         0.961538  (10707,)\n","67         0.960769  (13053,)\n","4          0.943456   (1040,)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["topUsers=pearsonDF.sort_values(by='similarityIndex', ascending=False)[0:50]\n","topUsers.head()"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["Now, let's start recommending movies to the input user.\n","\n","#### Rating of selected users to all movies\n","\n","We're going to do this by taking the weighted average of the ratings of the movies using the Pearson Correlation as the weight. But to do this, we first need to get the movies watched by the users in our **pearsonDF** from the ratings dataframe and then store their correlation in a new column called \\_similarityIndex\". This is achieved below by merging of these two tables.\n"]},{"cell_type":"code","execution_count":25,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"scrolled":true},"outputs":[{"ename":"ValueError","evalue":"You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m topUsersRating\u001b[38;5;241m=\u001b[39m\u001b[43mtopUsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mratings_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muserId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muserId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minner\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m topUsersRating\u001b[38;5;241m.\u001b[39mhead()\n","File \u001b[1;32mc:\\Users\\oseis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:9843\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m   9824\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   9825\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m   9826\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9839\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   9840\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   9841\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[1;32m-> 9843\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9844\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9852\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9857\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\oseis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:142\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    141\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m--> 142\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n","File \u001b[1;32mc:\\Users\\oseis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:735\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    727\u001b[0m (\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[0;32m    729\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[0;32m    731\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n\u001b[0;32m    733\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m--> 735\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[1;32mc:\\Users\\oseis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1387\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1381\u001b[0m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[0;32m   1382\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   1383\u001b[0m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1384\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1385\u001b[0m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1386\u001b[0m     ):\n\u001b[1;32m-> 1387\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n","\u001b[1;31mValueError\u001b[0m: You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat"]}],"source":["topUsersRating=topUsers.merge(ratings_df, left_on='userId', right_on='userId', how='inner')\n","topUsersRating.head()"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["Now all we need to do is simply multiply the movie rating by its weight (the similarity index), then sum up the new ratings and divide it by the sum of the weights.\n","\n","We can easily do this by simply multiplying two columns, then grouping up the dataframe by movieId and then dividing two columns:\n","\n","It shows the idea of all similar users to candidate movies for the input user:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["#Multiplies the similarity by the user's ratings\n","topUsersRating['weightedRating'] = topUsersRating['similarityIndex']*topUsersRating['rating']\n","topUsersRating.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["#Applies a sum to the topUsers after grouping it up by userId\n","tempTopUsersRating = topUsersRating.groupby('movieId').sum()[['similarityIndex','weightedRating']]\n","tempTopUsersRating.columns = ['sum_similarityIndex','sum_weightedRating']\n","tempTopUsersRating.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["#Creates an empty dataframe\n","recommendation_df = pd.DataFrame()\n","#Now we take the weighted average\n","recommendation_df['weighted average recommendation score'] = tempTopUsersRating['sum_weightedRating']/tempTopUsersRating['sum_similarityIndex']\n","recommendation_df['movieId'] = tempTopUsersRating.index\n","recommendation_df.head()"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["Now let's sort it and see the top 20 movies that the algorithm recommended!\n"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"scrolled":false},"outputs":[],"source":["recommendation_df = recommendation_df.sort_values(by='weighted average recommendation score', ascending=False)\n","recommendation_df.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"scrolled":true},"outputs":[],"source":["movies_df.loc[movies_df['movieId'].isin(recommendation_df.head(10)['movieId'].tolist())]"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["### Advantages and Disadvantages of Collaborative Filtering\n","\n","##### Advantages\n","\n","*   Takes other user's ratings into consideration\n","*   Doesn't need to study or extract information from the recommended item\n","*   Adapts to the user's interests which might change over time\n","\n","##### Disadvantages\n","\n","*   Approximation function can be slow\n","*   There might be a low amount of users to approximate\n","*   Privacy issues when trying to learn the user's preferences\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"widgets":{"state":{},"version":"1.1.2"}},"nbformat":4,"nbformat_minor":2}
